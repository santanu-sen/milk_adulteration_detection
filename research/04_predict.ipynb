{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\admin\\\\Desktop\\\\JI\\\\Project\\\\capstone\\\\milk_adulteration_detection\\\\research'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from detection.components.data_ingestion import DataIngestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_params(config_path):\n",
    "    with open(config_path) as yaml_file:\n",
    "        config = yaml.safe_load(yaml_file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionPipeline:\n",
    "    def __init__(self, filename, directory):\n",
    "        self.filename = filename\n",
    "        self.directory = directory\n",
    "        self.config_path = Path('C:\\\\Users\\\\admin\\\\Desktop\\\\JI\\\\Project\\\\capstone\\\\milk_adulteration_detection\\\\params.yaml')\n",
    "    \n",
    "    \n",
    "    def pad_to_size(self, image, desired_height, desired_width):\n",
    "        # Get the current size of the image\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # Calculate the amount of padding needed\n",
    "        pad_height = max(0, desired_height - height)\n",
    "        pad_width = max(0, desired_width - width)\n",
    "\n",
    "        # Calculate the padding amounts for top, bottom, left, and right sides\n",
    "        top_pad = pad_height // 2\n",
    "        bottom_pad = pad_height - top_pad\n",
    "        left_pad = pad_width // 2\n",
    "        right_pad = pad_width - left_pad\n",
    "\n",
    "        # Pad the image with zeros\n",
    "        padded_image = cv2.copyMakeBorder(image, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "        return padded_image\n",
    "    \n",
    "    \n",
    "    def find_contours1(self, image):\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply a threshold or any other preprocessing if needed\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Sort contours based on their area in descending order and select top two contours\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:2] if len(contours) >= 2 else contours\n",
    "\n",
    "        # Filter contours with an area less than 18000\n",
    "        contours = [contour for contour in contours if cv2.contourArea(contour) >= 10000]\n",
    "\n",
    "        # Initialize variables for left and right contours\n",
    "        left_cropped_image = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "        right_cropped_image = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "\n",
    "        if len(contours) == 1:\n",
    "            left_contour = contours[0]\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(left_contour)\n",
    "            # Crop left region\n",
    "            left_cropped_image = image[y1:y1+h1, x1:x1+w1]\n",
    "        elif len(contours) == 2:\n",
    "            # Sort contours by x-coordinate\n",
    "            contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "            left_contour = contours[0]\n",
    "            right_contour = contours[1]\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(left_contour)\n",
    "            x2, y2, w2, h2 = cv2.boundingRect(right_contour)\n",
    "            # Crop left and right regions\n",
    "            left_cropped_image = image[y1:y1+h1, x1:x1+w1]\n",
    "            right_cropped_image = image[y2:y2+h2, x2:x2+w2]\n",
    "\n",
    "            # Pad the cropped images to 200x200\n",
    "            left_cropped_image = self.pad_to_size(left_cropped_image, 200, 200)\n",
    "            right_cropped_image = self.pad_to_size(right_cropped_image, 200, 200)\n",
    "\n",
    "            #cropping to 50x50 to get only the center portion of the patch\n",
    "            left_cropped_image = left_cropped_image[75:125,75:125,:]\n",
    "            right_cropped_image = right_cropped_image[75:125,75:125,:]\n",
    "\n",
    "            if left_cropped_image.all() == 0:\n",
    "                left_cropped_image = None\n",
    "\n",
    "            if right_cropped_image.all() == 0:\n",
    "                right_cropped_image = None\n",
    "\n",
    "        return left_cropped_image, right_cropped_image\n",
    "\n",
    "    def preprocess_image(self):\n",
    "        image = DataIngestion.read_image(self, self.directory)\n",
    "        img_h, img_g = DataIngestion.segment_strip1(self, image)\n",
    "        \n",
    "        img_cv = cv2.cvtColor(img_g, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract features from RGB\n",
    "        r, g, b = cv2.split(img_cv)\n",
    "        average_r = r.mean()\n",
    "        average_g = g.mean()\n",
    "        average_b = b.mean()\n",
    "\n",
    "        # Convert RGB image to HSV\n",
    "        hsv_img = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv_img)\n",
    "        average_h = h.mean()\n",
    "        average_s = s.mean()\n",
    "        average_v = v.mean()\n",
    "\n",
    "        # Convert RGB image to LAB\n",
    "        lab_img = cv2.cvtColor(img_cv, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b_lab = cv2.split(lab_img)\n",
    "        average_l = l.mean()\n",
    "        average_a = a.mean()\n",
    "        average_b_lab = b_lab.mean()\n",
    "\n",
    "        # Combine all features into a single array\n",
    "        features = np.array([average_r, average_g, average_b, average_h, average_s, average_v, average_l, average_a, average_b_lab])\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        # Load the model\n",
    "        model = joblib.load(Path('C:\\\\Users\\\\admin\\\\Desktop\\\\JI\\\\Project\\\\capstone\\\\milk_adulteration_detection\\\\artifacts\\\\training\\\\model.joblib'))\n",
    "\n",
    "        # Read the threshold from the config file\n",
    "        config = read_params(self.config_path)\n",
    "        threshold = config['THRESHOLD']\n",
    "\n",
    "        # Preprocess the image\n",
    "        image_features = self.preprocess_image()\n",
    "\n",
    "        # Predict using the model\n",
    "        probabilities = model.predict_proba(image_features.reshape(1, -1))  # Assuming the model expects a 2D array\n",
    "\n",
    "        # Check if the probability of the positive class (e.g., index 1) exceeds the threshold\n",
    "        result = probabilities[0][1] > threshold\n",
    "        \n",
    "        # Interpret the result\n",
    "        if result:\n",
    "            prediction = 'Adulterated'\n",
    "        else:\n",
    "            prediction = 'Not Adulterated'\n",
    "\n",
    "        return [{\"image\": prediction}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': 'Not Adulterated'}]\n"
     ]
    }
   ],
   "source": [
    "directory = \"C:\\\\Users\\\\admin\\\\Desktop\\\\JI\\\\Project\\\\capstone\\\\milk_adulteration_detection\\\\42.19.jpg\"\n",
    "filename = \"42.19.jpg\"\n",
    "\n",
    "pipeline = PredictionPipeline(filename=filename, directory=directory)\n",
    "prediction = pipeline.predict()\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
